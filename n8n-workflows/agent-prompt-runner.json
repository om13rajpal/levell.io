{
  "name": "Agent Prompt Runner",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "run-agent-prompt",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [250, 300],
      "webhookId": "run-agent-prompt"
    },
    {
      "parameters": {
        "method": "GET",
        "url": "=https://levell-io.vercel.app/api/prompts/{{ $json.body.prompt_id }}",
        "options": {}
      },
      "id": "fetch-prompt",
      "name": "Fetch Prompt from API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [450, 300]
    },
    {
      "parameters": {
        "method": "GET",
        "url": "=https://levell-io.vercel.app/api/transcripts/{{ $('Webhook').first().json.body.transcript_id }}",
        "options": {}
      },
      "id": "fetch-transcript",
      "name": "Fetch Transcript",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [650, 300]
    },
    {
      "parameters": {
        "jsCode": "const webhookData = $('Webhook').first().json.body;\nconst prompt = $('Fetch Prompt from API').first().json;\nconst transcript = $input.first().json;\n\n// Use test transcript if in test mode\nconst transcriptContent = webhookData.test_mode && webhookData.test_transcript \n  ? webhookData.test_transcript \n  : (transcript.content || transcript.transcript || '');\n\nreturn {\n  prompt_id: prompt.id,\n  prompt_version: prompt.version || 1,\n  agent_type: prompt.agent_type,\n  prompt_content: prompt.prompt_content,\n  transcript: transcriptContent,\n  transcript_id: webhookData.transcript_id,\n  user_id: webhookData.user_id,\n  test_mode: webhookData.test_mode || false\n};"
      },
      "id": "prepare-prompt",
      "name": "Prepare Prompt Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [850, 300]
    },
    {
      "parameters": {
        "model": "gpt-4o",
        "options": {
          "temperature": 0.3,
          "maxTokens": 4096,
          "responseFormat": "json_object"
        },
        "messages": {
          "values": [
            {
              "role": "system",
              "content": "={{ $json.prompt_content }}"
            },
            {
              "role": "user",
              "content": "Analyze this sales call transcript:\n\n{{ $json.transcript }}"
            }
          ]
        }
      },
      "id": "openai-call",
      "name": "OpenAI Chat",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [1050, 300],
      "credentials": {
        "openAiApi": {
          "id": "s4JHez4r5GFcPdkg",
          "name": "Seb"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const promptData = $('Prepare Prompt Data').first().json;\nconst aiResponse = $input.first().json;\n\n// Parse the AI response\nlet outputData = {};\ntry {\n  outputData = JSON.parse(aiResponse.message?.content || '{}');\n} catch (e) {\n  outputData = { raw_output: aiResponse.message?.content };\n}\n\nconst usage = aiResponse.usage || {};\n\n// Calculate cost (GPT-4o pricing: $2.50/1M input, $10.00/1M output)\nconst inputTokens = usage.prompt_tokens || 0;\nconst outputTokens = usage.completion_tokens || 0;\nconst inputCost = (inputTokens * 2.5) / 1000000;\nconst outputCost = (outputTokens * 10) / 1000000;\nconst totalCost = inputCost + outputCost;\n\nreturn {\n  prompt_id: promptData.prompt_id,\n  prompt_version: promptData.prompt_version,\n  agent_type: promptData.agent_type,\n  run_type: 'n8n',\n  is_test_run: promptData.test_mode,\n  transcript_id: promptData.transcript_id,\n  user_id: promptData.user_id,\n  output: aiResponse.message?.content || '',\n  output_data: outputData,\n  input_tokens: inputTokens,\n  output_tokens: outputTokens,\n  prompt_tokens: inputTokens,\n  completion_tokens: outputTokens,\n  cost_usd: totalCost,\n  total_cost: totalCost,\n  model: 'gpt-4o',\n  status: 'completed'\n};"
      },
      "id": "prepare-run-data",
      "name": "Prepare Run Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1250, 300]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://levell-io.vercel.app/api/agent-runs",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"prompt_id\": \"{{ $json.prompt_id }}\",\n  \"prompt_version\": {{ $json.prompt_version }},\n  \"agent_type\": \"{{ $json.agent_type }}\",\n  \"run_type\": \"{{ $json.run_type }}\",\n  \"is_test_run\": {{ $json.is_test_run }},\n  \"transcript_id\": {{ $json.transcript_id || 'null' }},\n  \"output\": {{ JSON.stringify($json.output) }},\n  \"input_tokens\": {{ $json.input_tokens }},\n  \"output_tokens\": {{ $json.output_tokens }},\n  \"prompt_tokens\": {{ $json.prompt_tokens }},\n  \"completion_tokens\": {{ $json.completion_tokens }},\n  \"cost_usd\": {{ $json.cost_usd }},\n  \"total_cost\": {{ $json.total_cost }},\n  \"model\": \"{{ $json.model }}\",\n  \"status\": \"{{ $json.status }}\"\n}",
        "options": {}
      },
      "id": "save-run",
      "name": "Save Run to API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1450, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"run_id\": \"{{ $json.id }}\",\n  \"agent_type\": \"{{ $('Prepare Run Data').first().json.agent_type }}\",\n  \"message\": \"Agent run completed\",\n  \"token_usage\": {\n    \"input\": {{ $('Prepare Run Data').first().json.input_tokens }},\n    \"output\": {{ $('Prepare Run Data').first().json.output_tokens }}\n  },\n  \"cost_usd\": {{ $('Prepare Run Data').first().json.cost_usd }}\n}"
      },
      "id": "respond",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [1650, 300]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Fetch Prompt from API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Prompt from API": {
      "main": [
        [
          {
            "node": "Fetch Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Transcript": {
      "main": [
        [
          {
            "node": "Prepare Prompt Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Prompt Data": {
      "main": [
        [
          {
            "node": "OpenAI Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat": {
      "main": [
        [
          {
            "node": "Prepare Run Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Run Data": {
      "main": [
        [
          {
            "node": "Save Run to API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Run to API": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  }
}
