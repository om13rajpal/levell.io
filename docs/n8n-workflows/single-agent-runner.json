{
  "name": "Single Agent Prompt Runner",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "run-agent-prompt",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "d26f2f41-5eb8-4ed5-a102-3062bf4013fc",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [-240, 32],
      "webhookId": "run-agent-prompt"
    },
    {
      "parameters": {
        "url": "=https://levell-io.vercel.app/api/prompts/{{ $json.body.prompt_id }}",
        "options": {}
      },
      "id": "01aeec36-aff1-43c0-83cc-a768a9cd228c",
      "name": "Fetch Prompt from API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [-16, 32]
    },
    {
      "parameters": {
        "url": "=https://levell-io.vercel.app/api/transcripts/{{ $('Webhook').first().json.body.transcript_id }}",
        "options": {}
      },
      "id": "bc5d12ec-2f17-4c54-b464-b7d937be6c8a",
      "name": "Fetch Transcript",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [208, 32]
    },
    {
      "parameters": {
        "jsCode": "const webhookData = $('Webhook').first().json.body;\nconst prompt = $('Fetch Prompt from API').first().json;\nconst transcript = $input.first().json;\n\n// Use test transcript if in test mode, otherwise use fetched transcript\nconst transcriptContent = webhookData.test_mode && webhookData.test_transcript \n  ? webhookData.test_transcript \n  : (transcript.content || transcript.transcript || '');\n\nreturn {\n  prompt_id: prompt.id,\n  prompt_version: prompt.version || 1,\n  agent_type: prompt.agent_type,\n  prompt_content: prompt.prompt_content,\n  transcript: transcriptContent,\n  transcript_id: webhookData.transcript_id,\n  user_id: webhookData.user_id,\n  test_mode: webhookData.test_mode || false\n};"
      },
      "id": "d974ff7c-52b4-4b83-aa96-080bfe3144fc",
      "name": "Prepare Prompt Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [432, 32]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "GPT-4.1"
        },
        "messages": {
          "values": [
            {
              "content": "={{ $json.prompt_content }}",
              "role": "system"
            },
            {
              "content": "Analyze this sales call transcript:\n\n{{ $json.transcript }}"
            }
          ]
        },
        "options": {
          "maxTokens": 4096,
          "temperature": 0.3
        }
      },
      "id": "35d76acc-fa18-4fae-b470-fe048ba53a27",
      "name": "OpenAI Chat",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [656, 32],
      "credentials": {
        "openAiApi": {
          "id": "YOUR_OPENAI_CREDENTIAL_ID",
          "name": "OpenAI API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const promptData = $('Prepare Prompt Data').first().json;\nconst aiResponse = $input.first().json;\n\n// Parse the AI response\nlet outputData = {};\ntry {\n  outputData = JSON.parse(aiResponse.message?.content || '{}');\n} catch (e) {\n  outputData = { raw_output: aiResponse.message?.content };\n}\n\nconst usage = aiResponse.usage || {};\n\n// Calculate cost (GPT-4o pricing: $2.50/1M input, $10.00/1M output)\nconst inputTokens = usage.prompt_tokens || 0;\nconst outputTokens = usage.completion_tokens || 0;\nconst inputCost = (inputTokens * 2.5) / 1000000;\nconst outputCost = (outputTokens * 10) / 1000000;\nconst totalCost = inputCost + outputCost;\n\nreturn {\n  prompt_id: promptData.prompt_id,\n  prompt_version: promptData.prompt_version,\n  agent_type: promptData.agent_type,\n  run_type: 'n8n',\n  is_test_run: promptData.test_mode,\n  transcript_id: promptData.transcript_id,\n  user_id: promptData.user_id,\n  output: aiResponse.message?.content || '',\n  output_data: outputData,\n  input_tokens: inputTokens,\n  output_tokens: outputTokens,\n  prompt_tokens: inputTokens,\n  completion_tokens: outputTokens,\n  cost_usd: totalCost,\n  total_cost: totalCost,\n  model: 'gpt-4o',\n  status: 'completed'\n};"
      },
      "id": "8293c079-1e29-4a42-bf54-46ff01ed8352",
      "name": "Prepare Run Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1008, 32]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://levell-io.vercel.app/api/agent-runs",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"prompt_id\": \"{{ $json.prompt_id }}\",\n  \"agent_type\": \"{{ $json.agent_type }}\",\n  \"prompt_sent\": {{ JSON.stringify($('Prepare Prompt Data').first().json.prompt_content) }},\n  \"output\": {{ JSON.stringify($json.output) }},\n  \"model\": \"{{ $json.model }}\",\n  \"prompt_tokens\": {{ $json.prompt_tokens }},\n  \"completion_tokens\": {{ $json.completion_tokens }},\n  \"transcript_id\": {{ $json.transcript_id || 'null' }},\n  \"context_type\": \"{{ $json.run_type }}\",\n  \"status\": \"{{ $json.status }}\",\n  \"metadata\": {\n    \"prompt_version\": {{ $json.prompt_version }},\n    \"is_test_run\": {{ $json.is_test_run }},\n    \"cost_usd\": {{ $json.cost_usd }},\n    \"total_cost\": {{ $json.total_cost }},\n    \"input_tokens\": {{ $json.input_tokens }},\n    \"output_tokens\": {{ $json.output_tokens }}\n  }\n}",
        "options": {}
      },
      "id": "724bafdb-da38-43e3-b364-d50d5c442cc7",
      "name": "Save Run to API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1232, 32]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"run_id\": \"{{ $json.id }}\",\n  \"agent_type\": \"{{ $('Prepare Run Data').first().json.agent_type }}\",\n  \"message\": \"Agent run completed\",\n  \"token_usage\": {\n    \"input\": {{ $('Prepare Run Data').first().json.input_tokens }},\n    \"output\": {{ $('Prepare Run Data').first().json.output_tokens }}\n  },\n  \"cost_usd\": {{ $('Prepare Run Data').first().json.cost_usd }}\n}",
        "options": {}
      },
      "id": "b9c740de-ddc9-47b5-bf3e-543faa99e455",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [1456, 32]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Fetch Prompt from API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Prompt from API": {
      "main": [
        [
          {
            "node": "Fetch Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Transcript": {
      "main": [
        [
          {
            "node": "Prepare Prompt Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Prompt Data": {
      "main": [
        [
          {
            "node": "OpenAI Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat": {
      "main": [
        [
          {
            "node": "Prepare Run Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Run Data": {
      "main": [
        [
          {
            "node": "Save Run to API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Run to API": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "instanceId": "c86a0d6bd9b227eed8276ce29b9663c57febb48474b6bd9382a28ca9bde1b1c9"
  }
}
