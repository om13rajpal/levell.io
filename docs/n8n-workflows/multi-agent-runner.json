{
  "name": "Multi-Agent ScoreV2 Runner",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "scoreV2",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "a1b2c3d4-5e6f-7890-abcd-ef1234567890",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [-240, 32],
      "webhookId": "scoreV2"
    },
    {
      "parameters": {
        "url": "https://levell-io.vercel.app/api/prompts?active_only=true",
        "options": {}
      },
      "id": "b2c3d4e5-6f78-90ab-cdef-123456789012",
      "name": "Fetch All Prompts",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [-16, 32]
    },
    {
      "parameters": {
        "url": "=https://levell-io.vercel.app/api/transcripts/{{ $('Webhook').first().json.body.transcript_id }}",
        "options": {}
      },
      "id": "c3d4e5f6-7890-abcd-ef12-345678901234",
      "name": "Fetch Transcript",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [208, 32]
    },
    {
      "parameters": {
        "jsCode": "const webhookData = $('Webhook').first().json.body;\nconst promptsResponse = $('Fetch All Prompts').first().json;\nconst transcriptData = $input.first().json;\n\n// Get prompts array\nconst prompts = promptsResponse.prompts || [];\n\n// Use test transcript if in test mode, otherwise use fetched transcript\nconst transcriptContent = webhookData.test_mode && webhookData.test_transcript \n  ? webhookData.test_transcript \n  : (transcriptData.content || transcriptData.transcript || '');\n\n// Create an array of agent jobs - one for each prompt\nconst agentJobs = prompts.map(prompt => ({\n  prompt_id: prompt.id,\n  prompt_version: prompt.version || 1,\n  agent_type: prompt.agent_type,\n  prompt_content: prompt.prompt_content,\n  transcript: transcriptContent,\n  transcript_id: webhookData.transcript_id,\n  user_id: webhookData.user_id,\n  test_mode: webhookData.test_mode || false\n}));\n\nreturn agentJobs.map(job => ({ json: job }));"
      },
      "id": "d4e5f6a7-890a-bcde-f123-456789012345",
      "name": "Prepare All Agent Jobs",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [432, 32]
    },
    {
      "parameters": {
        "batchSize": 3,
        "options": {}
      },
      "id": "e5f6a7b8-90ab-cdef-1234-567890123456",
      "name": "Loop Over Agents",
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [656, 32]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "GPT-4.1"
        },
        "messages": {
          "values": [
            {
              "content": "={{ $json.prompt_content }}",
              "role": "system"
            },
            {
              "content": "Analyze this sales call transcript:\n\n{{ $json.transcript }}"
            }
          ]
        },
        "options": {
          "maxTokens": 4096,
          "temperature": 0.3
        }
      },
      "id": "f6a7b8c9-0abc-def1-2345-678901234567",
      "name": "OpenAI Chat",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [880, 32],
      "credentials": {
        "openAiApi": {
          "id": "YOUR_OPENAI_CREDENTIAL_ID",
          "name": "OpenAI API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Get the current agent job data (from before OpenAI call)\nconst agentJob = $('Loop Over Agents').first().json;\nconst aiResponse = $input.first().json;\n\n// Parse the AI response\nlet outputData = {};\ntry {\n  outputData = JSON.parse(aiResponse.message?.content || '{}');\n} catch (e) {\n  outputData = { raw_output: aiResponse.message?.content };\n}\n\nconst usage = aiResponse.usage || {};\n\n// Calculate cost (GPT-4o pricing: $2.50/1M input, $10.00/1M output)\nconst inputTokens = usage.prompt_tokens || 0;\nconst outputTokens = usage.completion_tokens || 0;\nconst inputCost = (inputTokens * 2.5) / 1000000;\nconst outputCost = (outputTokens * 10) / 1000000;\nconst totalCost = inputCost + outputCost;\n\nreturn {\n  prompt_id: agentJob.prompt_id,\n  prompt_version: agentJob.prompt_version,\n  agent_type: agentJob.agent_type,\n  prompt_sent: agentJob.prompt_content,\n  run_type: 'n8n',\n  is_test_run: agentJob.test_mode,\n  transcript_id: agentJob.transcript_id,\n  user_id: agentJob.user_id,\n  output: aiResponse.message?.content || '',\n  output_data: outputData,\n  input_tokens: inputTokens,\n  output_tokens: outputTokens,\n  prompt_tokens: inputTokens,\n  completion_tokens: outputTokens,\n  cost_usd: totalCost,\n  total_cost: totalCost,\n  model: 'gpt-4o',\n  status: 'completed'\n};"
      },
      "id": "a7b8c9d0-1bcd-ef12-3456-789012345678",
      "name": "Prepare Run Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1104, 32]
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "options": {}
      },
      "id": "b8c9d0e1-2cde-f123-4567-890123456789",
      "name": "Aggregate All Results",
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [1328, 160]
    },
    {
      "parameters": {
        "jsCode": "// Aggregate all run data into batch payload\nconst allItems = $input.all();\nconst runs = allItems.map(item => item.json);\n\n// Calculate totals\nconst totalInputTokens = runs.reduce((sum, r) => sum + (r.input_tokens || 0), 0);\nconst totalOutputTokens = runs.reduce((sum, r) => sum + (r.output_tokens || 0), 0);\nconst totalCostUsd = runs.reduce((sum, r) => sum + (r.cost_usd || 0), 0);\n\nreturn {\n  runs: runs,\n  total_input_tokens: totalInputTokens,\n  total_output_tokens: totalOutputTokens,\n  total_cost_usd: totalCostUsd,\n  agents_count: runs.length\n};"
      },
      "id": "c9d0e1f2-3def-1234-5678-901234567890",
      "name": "Prepare Batch Payload",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1552, 160]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://levell-io.vercel.app/api/agent-runs/batch",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"runs\": {{ JSON.stringify($json.runs) }},\n  \"total_cost_usd\": {{ $json.total_cost_usd }}\n}",
        "options": {}
      },
      "id": "d0e1f2a3-4ef0-1234-5678-901234567891",
      "name": "Save Batch to API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1776, 160]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"runs_saved\": {{ $json.runs_saved }},\n  \"agents_count\": {{ $('Prepare Batch Payload').first().json.agents_count }},\n  \"message\": \"Multi-agent analysis completed\",\n  \"token_usage\": {\n    \"total_input\": {{ $('Prepare Batch Payload').first().json.total_input_tokens }},\n    \"total_output\": {{ $('Prepare Batch Payload').first().json.total_output_tokens }}\n  },\n  \"total_cost_usd\": {{ $('Prepare Batch Payload').first().json.total_cost_usd }},\n  \"run_ids\": {{ JSON.stringify($json.ids || []) }}\n}",
        "options": {}
      },
      "id": "e1f2a3b4-5f01-2345-6789-012345678912",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [2000, 160]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Fetch All Prompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch All Prompts": {
      "main": [
        [
          {
            "node": "Fetch Transcript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Transcript": {
      "main": [
        [
          {
            "node": "Prepare All Agent Jobs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare All Agent Jobs": {
      "main": [
        [
          {
            "node": "Loop Over Agents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Agents": {
      "main": [
        [
          {
            "node": "OpenAI Chat",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Aggregate All Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat": {
      "main": [
        [
          {
            "node": "Prepare Run Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Run Data": {
      "main": [
        [
          {
            "node": "Loop Over Agents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate All Results": {
      "main": [
        [
          {
            "node": "Prepare Batch Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Batch Payload": {
      "main": [
        [
          {
            "node": "Save Batch to API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Batch to API": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "instanceId": "c86a0d6bd9b227eed8276ce29b9663c57febb48474b6bd9382a28ca9bde1b1c9"
  }
}
